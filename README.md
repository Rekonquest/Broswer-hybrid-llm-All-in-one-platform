# Hybrid LLM Platform

> A BrowserOS-inspired platform for running multiple LLMs with fine-grained security controls, inter-LLM collaboration, and sandboxed execution environments.

[![License](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue.svg)](LICENSE)
[![Rust](https://img.shields.io/badge/rust-1.75%2B-orange.svg)](https://www.rust-lang.org/)

## ğŸš€ Overview

The Hybrid LLM Platform is a comprehensive orchestration system for running multiple Language Learning Models (both local and cloud-based) with enterprise-grade security, permission management, and collaborative capabilities. Think of it as an operating system for LLMs.

### Key Features

- **ğŸ¤ Multi-LLM Collaboration**: LLMs can call each other for specialized tasks
- **ğŸ”’ Fine-Grained Security**: Extensive permission system with algorithmic guardrails
- **ğŸ–ï¸ Sandboxed Execution**: Firecracker-based microVMs for isolated code execution
- **ğŸŒ Hybrid Architecture**: Support for both local (llama.cpp) and cloud LLMs (Claude, GPT, Gemini)
- **ğŸ“š Built-in RAG**: PostgreSQL + pgvector for semantic document search
- **ğŸ¯ Developer-First**: Full root access by default with configurable safety controls
- **ğŸ“Š Audit Trail**: Complete logging of all LLM actions and permission requests

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Rust Orchestrator (Kernel)      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚       Message Bus (tokio)          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ LLM Pool â”‚  â”‚ Security â”‚  â”‚Context â”‚â”‚
â”‚  â”‚ Manager  â”‚  â”‚  Engine  â”‚  â”‚Manager â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚Filesystemâ”‚  â”‚ Sandbox  â”‚  â”‚   API  â”‚â”‚
â”‚  â”‚Interface â”‚  â”‚ Manager  â”‚  â”‚Gateway â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
         â–¼                    â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Local LLMsâ”‚        â”‚  Cloud APIs â”‚
  â”‚(llama.cpp)â”‚        â”‚Claude/GPT/  â”‚
  â”‚           â”‚        â”‚   Gemini    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Overview

| Component | Purpose | Technology |
|-----------|---------|------------|
| **Orchestrator** | Central message routing and coordination | Rust + Tokio |
| **LLM Pool** | Manages multiple LLM instances and load balancing | Rust |
| **Security Engine** | Permission management and guardrails | Rust + Regex |
| **Sandbox Manager** | Isolated code execution | Firecracker microVMs |
| **Context Manager** | Global and per-LLM context/memory | In-memory + PostgreSQL |
| **API Gateway** | Unified interface for cloud LLMs | Rust + reqwest |
| **Filesystem Interface** | Upload/download/RAG document management | Rust + notify |

## ğŸ¯ Use Cases

- **Multi-Model Development**: Use specialized models for different tasks (coding, security, analysis)
- **Secure AI Assistants**: LLMs with controlled system access and audit trails
- **Research & Experimentation**: Test different models and collaboration patterns
- **Privacy-First AI**: Run local models while optionally leveraging cloud APIs
- **Educational**: Learn about LLM orchestration and security

## ğŸ› ï¸ Installation

### Prerequisites

- **Rust**: 1.75 or later
- **PostgreSQL**: 14+ with pgvector extension
- **Firecracker** (optional for MVP, required for full sandbox support)
- **llama.cpp** (for local models)

### Quick Start

```bash
# Clone the repository
git clone https://github.com/Rekonquest/browser-privacy.git
cd browser-privacy

# Build the project
cargo build --release

# Set up PostgreSQL with pgvector (see docs/setup.md)

# Run the orchestrator
./target/release/hybrid-llm
```

## âš™ï¸ Configuration

### Permission System

The platform uses a layered permission system:

1. **Global Defaults**: Apply to all LLMs by default
2. **Per-LLM Overrides**: Custom permissions for specific models
3. **Runtime Requests**: LLMs can request additional permissions with justification

Example permission configuration:

```yaml
file_system:
  read: ["/home/user/downloads/*", "/rag/*"]
  write: ["/home/user/downloads/*"]
  execute: ["/usr/bin/python", "/usr/bin/node"]

network:
  inbound: true
  outbound: true
  require_approval: ["*"]  # All network access requires user approval

commands:
  whitelist: ["git", "npm", "python", "cargo", "ls", "cat"]
  blacklist: ["rm -rf /", "sudo", "dd", "mkfs"]
  require_explanation: true

resources:
  max_cpu_percent: 80
  max_memory_gb: 8
  max_disk_gb: 50
```

### Security Guardrails

Built-in algorithmic guardrails automatically detect:

- âš ï¸ Dangerous file deletions (`rm -rf /`)
- âš ï¸ Privilege escalation (`sudo`)
- âš ï¸ Low-level disk operations (`dd`, `mkfs`)
- âš ï¸ Potential data exfiltration patterns
- âš ï¸ Hardcoded credentials
- âš ï¸ Shell injection attempts

### Lockdown Mode

The system can enter lockdown mode when:

- Policy violations are detected
- Suspicious patterns emerge
- Resource limits are exceeded
- User presses panic button
- Multiple failed permission requests (>5)

In lockdown mode:
- All LLM operations pause
- System reverts to read-only mode
- Incident is flagged for human review
- User authentication required to resume

## ğŸ¤– Multi-LLM Collaboration

LLMs can collaborate to solve complex tasks:

```
User: "Build a secure REST API"
  â†“
Generalist LLM: Analyzes request
  â†“
Generalist â†’ Coder LLM: "Write the API implementation"
  â†“
Coder â†’ Security LLM: "Review this code for vulnerabilities"
  â†“
Security LLM: Provides feedback
  â†“
Coder: Revises implementation
  â†“
User: Receives final, security-reviewed code
```

## ğŸ“¦ Sandboxed Execution

Code execution happens in isolated Firecracker microVMs:

1. LLM requests sandbox
2. System creates isolated microVM
3. Code executes in sandbox
4. LLM requests artifact transfer
5. User reviews and approves
6. Files move to main system
7. Sandbox destroyed

## ğŸ”Œ Supported LLM Providers

### Local Models (via llama.cpp)
- Qwen 2.5 Coder (8B, 14B, 32B)
- Qwen 2.5 (3B, 7B, 14B)
- RedReamer (3B - specialized for security)
- DeepSeek Coder
- Llama 3.1/3.2
- Any GGUF-format model

### Cloud APIs
- âœ… **Claude** (Anthropic) - Implemented
- âœ… **ChatGPT** (OpenAI) - Implemented
- âœ… **Gemini** (Google) - Implemented
- ğŸ”œ Mistral API
- ğŸ”œ Cohere API

## ğŸ“ Project Structure

```
browser-privacy/
â”œâ”€â”€ Cargo.toml              # Workspace configuration
â”œâ”€â”€ orchestrator/           # Main binary
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.rs
â”‚       â”œâ”€â”€ message_bus.rs
â”‚       â”œâ”€â”€ router.rs
â”‚       â””â”€â”€ orchestrator.rs
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ common/            # Shared types and traits
â”‚   â”œâ”€â”€ llm-pool/          # LLM management
â”‚   â”œâ”€â”€ security-engine/   # Permissions & guardrails
â”‚   â”œâ”€â”€ context-manager/   # Memory & RAG
â”‚   â”œâ”€â”€ api-gateway/       # Cloud LLM adapters
â”‚   â”œâ”€â”€ filesystem-interface/
â”‚   â””â”€â”€ sandbox-manager/   # Firecracker integration
â”œâ”€â”€ docs/                  # Documentation
â””â”€â”€ scripts/               # Utility scripts
```

## ğŸš¦ Current Status: MVP Foundation

### âœ… Completed
- [x] Core orchestrator with message bus
- [x] LLM pool management and routing
- [x] Security engine with guardrails
- [x] Permission system (file, network, command, resource)
- [x] API Gateway (Claude, OpenAI, Gemini)
- [x] Context manager foundation
- [x] Filesystem interface
- [x] Sandbox manager (placeholder for Firecracker)
- [x] Audit logging

### ğŸš§ In Progress
- [ ] PostgreSQL + pgvector integration for RAG
- [ ] llama.cpp integration
- [ ] Actual Firecracker microVM implementation
- [ ] Tauri UI development
- [ ] File watcher for auto-RAG indexing

### ğŸ”® Roadmap
- [ ] Streaming responses from all LLM providers
- [ ] Advanced load balancing and resource optimization
- [ ] Model performance metrics
- [ ] Plugin system for extensions
- [ ] Multi-user support
- [ ] Web-based UI dashboard
- [ ] Model marketplace/discovery

## ğŸ¤ Contributing

This is a developer-first project. Contributions are welcome!

### Development Setup

```bash
# Install Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Clone and build
git clone https://github.com/Rekonquest/browser-privacy.git
cd browser-privacy
cargo build

# Run tests
cargo test

# Check code
cargo clippy
```

## ğŸ“„ License

Licensed under either of:

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE))
- MIT License ([LICENSE-MIT](LICENSE-MIT))

at your option.

## ğŸ™ Acknowledgments

- **llama.cpp** for efficient local model inference
- **Firecracker** for secure microVM technology
- **Tokio** for async runtime
- **PostgreSQL & pgvector** for RAG capabilities

## ğŸ“ Contact

- Issues: [GitHub Issues](https://github.com/Rekonquest/browser-privacy/issues)
- Discussions: [GitHub Discussions](https://github.com/Rekonquest/browser-privacy/discussions)

---

**Note**: This is an MVP foundation. Core components are functional but some features (Firecracker integration, UI, full RAG) are in development. See the roadmap above for details.
